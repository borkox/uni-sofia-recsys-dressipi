{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74c05a9",
   "metadata": {},
   "source": [
    "## Baseline (random behavior)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0307b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e82322",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases_df = pd.read_csv(\"../data/dressipi_recsys2022/train_purchases.csv\", parse_dates=['date'])\n",
    "train_sessions_df = pd.read_csv(\"../data/dressipi_recsys2022/train_sessions.csv\" , parse_dates=['date'])\n",
    "item_features_df = pd.read_csv(\"../data/dressipi_recsys2022/item_features.csv\")\n",
    "candidate_items_df = pd.read_csv(\"../data/dressipi_recsys2022/candidate_items.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95e1c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##  train_purchases_df is for training, but we can use 5% for testing our baseline\n",
    "_, test_df = train_test_split(train_purchases_df, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c01211",
   "metadata": {},
   "source": [
    "## The task is to submit a csv that has 100 ranked predictions for each query session.\n",
    "Header and columns as in the example below. Header is required. The order of rows does not matter for the evaluation system but we recommend to sort the file by session_id and rank for easier manual inspection. \n",
    "<pre>\n",
    "session_id,item_id,rank\n",
    "1,100,1\n",
    "1,105,2\n",
    "1,107,3\n",
    "...\n",
    "1,101,100\n",
    "2,108,1\n",
    "2,107,2\n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b88f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df['session_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6db4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_item_ids = \\\n",
    "     list(train_sessions_df['item_id'].value_counts()[0:100].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the resulting dataframe in wanted format\n",
    "# by iterating all sessions and for each session from 1 too 100\n",
    "\n",
    "## itertools.product(X,Y,Z) is exploring all possible combinations from arrays X,Y,Z\n",
    "\n",
    "result_df = pd.DataFrame(product(test_df['session_id'], range(0,1), range(1, 101)))\n",
    "result_df.rename(columns = {0:'session_id', 1:'item_id', 2: 'rank'}, inplace = True)\n",
    "\n",
    "result_df['item_id'] = result_df.apply(lambda x: top_100_item_ids[x['rank']-1], axis=1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "826d521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mrr (Mean reciprocal rank)\n",
    "def calc_mrr(result_df, test_df):\n",
    "    mrr = 0\n",
    "    # Iterate all sessions\n",
    "    for sess_id in test_df['session_id']:\n",
    "        # Make view for only this session with all ranked\n",
    "        ranked = result_df[result_df['session_id']==sess_id]['item_id'].reset_index(drop=True)\n",
    "        real_item_id = test_df[test_df['session_id']==sess_id]['item_id'].reset_index(drop=True)[0] \n",
    "        first_rank = 100\n",
    "        found_t = ranked[ranked == real_item_id]\n",
    "        if len(found_t)!=0 :\n",
    "            first_rank = found_t.index[0]+1\n",
    "        mrr =mrr+ 1/first_rank\n",
    "        \n",
    "    mrr = mrr / test_df['session_id'].nunique()\n",
    "    return mrr\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8f4381da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of method is commented\n",
    "#calc_mrr(pd.DataFrame.from_dict({'session_id':[1,1,2,2,2,3,3,3], 'item_id':[1,2,3,4,5,6,7,8]}),\\\n",
    "#                     pd.DataFrame.from_dict({'session_id':[1,2,3], 'item_id':[2,5,8]}))\n",
    "#(1/2 + 1/3 + 1/100)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c797f6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01040975278319632"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is taking too long to calculate for the whole thing\n",
    "calc_mrr(result_df, test_df[0:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1793d5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010319511469477688"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mrr(result_df, test_df[45000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc884a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
