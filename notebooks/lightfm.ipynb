{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74c05a9",
   "metadata": {},
   "source": [
    "## LightFM recommendation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0307b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e82322",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases_df = pd.read_csv(\"../data/dressipi_recsys2022/train_purchases.csv\", parse_dates=['date'])\n",
    "train_sessions_df = pd.read_csv(\"../data/dressipi_recsys2022/train_sessions.csv\" , parse_dates=['date'])\n",
    "item_features_df = pd.read_csv(\"../data/dressipi_recsys2022/item_features.csv\")\n",
    "candidate_items_df = pd.read_csv(\"../data/dressipi_recsys2022/candidate_items.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b14d78",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a57743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_p_df)=980000 train purchases\n",
      "len(test_p_df)=20000   test purchases\n"
     ]
    }
   ],
   "source": [
    "# Test set is\n",
    "train_p_df, test_p_df = train_test_split(train_purchases_df, test_size=0.02)\n",
    "#test_sessions_set = set(test_p_df['session_id'])\n",
    "\n",
    "#train_s_df = train_sessions_df[~train_sessions_df['session_id'].isin(test_sessions_set)]\n",
    "#test_s_df = train_sessions_df[train_sessions_df['session_id'].isin(test_sessions_set)]\n",
    "\n",
    "#print(f\"len(test_sessions_set)={len(test_sessions_set)}\")\n",
    "print(f\"len(train_p_df)={len(train_p_df)} train purchases\")\n",
    "print(f\"len(test_p_df)={len(test_p_df)}   test purchases\")\n",
    "#print(f\"len(train_s_df)={len(train_s_df)} train sessions\")\n",
    "#print(f\"len(test_s_df)={len(test_s_df)}   test sessions\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c01211",
   "metadata": {},
   "source": [
    "## The task is to submit a csv that has 100 ranked predictions for each query session.\n",
    "Header and columns as in the example below. Header is required. The order of rows does not matter for the evaluation system but we recommend to sort the file by session_id and rank for easier manual inspection. \n",
    "<pre>\n",
    "session_id,item_id,rank\n",
    "1,100,1\n",
    "1,105,2\n",
    "1,107,3\n",
    "...\n",
    "1,101,100\n",
    "2,108,1\n",
    "2,107,2\n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b88f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightfm in /home/bobi/anaconda3/lib/python3.9/site-packages (1.16)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (1.8.0)\n",
      "Requirement already satisfied: requests in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (2.26.0)\n",
      "Requirement already satisfied: scikit-learn in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (0.24.2)\n",
      "Requirement already satisfied: numpy in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (1.22.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (2.0.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/bobi/anaconda3/lib/python3.9/site-packages (from scikit-learn->lightfm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from scikit-learn->lightfm) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca4dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826d521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Calculate Mrr (Mean reciprocal rank)\n",
    "def calc_mrr(result_df, test_df):\n",
    "    mrr = 0\n",
    "    # Iterate all sessions\n",
    "    for sess_id in tqdm(test_df['session_id']):\n",
    "        # Make view for only this session with all ranked\n",
    "        ranked = result_df[result_df['session_id']==sess_id]['item_id'].reset_index(drop=True)\n",
    "        real_item_id = test_df[test_df['session_id']==sess_id]['item_id'].reset_index(drop=True)[0] \n",
    "        first_rank = 100\n",
    "        found_t = ranked[ranked == real_item_id]\n",
    "        if len(found_t)!=0 :\n",
    "            first_rank = found_t.index[0]+1\n",
    "        #    print(f'sess_id={sess_id},real_item_id={real_item_id},first_rank={first_rank}')\n",
    "        #else:\n",
    "        #    print(f'sess_id={sess_id},real_item_id={real_item_id}, not found')\n",
    "            \n",
    "        mrr =mrr+ 1/first_rank\n",
    "        \n",
    "    mrr = mrr / test_df['session_id'].nunique()\n",
    "    return mrr\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4381da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of method is commented\n",
    "#calc_mrr(pd.DataFrame.from_dict({'session_id':[1,1,2,2,2,3,3,3], 'item_id':[1,2,3,4,5,6,7,8]}),\\\n",
    "#                     pd.DataFrame.from_dict({'session_id':[1,2,3], 'item_id':[2,5,8]}))\n",
    "#(1/2 + 1/3 + 1/100)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c797f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightfm.data import Dataset\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b79603",
   "metadata": {},
   "source": [
    "## Start building the feature for light FM\n",
    "User features are of the form tuple iterable tuple (session_id, [month, hour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc884a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (3, [])\n",
       "1    (13, [])\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions_df['month']='m' + train_sessions_df['date'].dt.month.apply(str)\n",
    "train_sessions_df['hour']='h' + train_sessions_df['date'].dt.hour.apply(str)\n",
    "\n",
    "# Aggregate by sessionId and add hour and month as list of features\n",
    "user_features = train_sessions_df.groupby('session_id').agg(\n",
    "    session_id=pd.NamedAgg(column=\"session_id\", aggfunc=\"min\"),\n",
    "    month=pd.NamedAgg(column=\"month\", aggfunc=set),\n",
    "    hour=pd.NamedAgg(column=\"hour\", aggfunc=set),\n",
    ").reset_index(drop=True).apply( \\\n",
    "        lambda row: (row['session_id'], []), axis = 1)\n",
    "        #lambda row: (row['session_id'], list(row['month']) + (list(row['hour']))), axis = 1)\n",
    "\n",
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab20e17",
   "metadata": {},
   "source": [
    "Item features are tuples of this form: iterable tuple (item_id, [category1-value1, category2-value2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaeaad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb5212ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 23691/23691 [00:00<00:00, 139836.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      (2, [])\n",
       "1      (3, [])\n",
       "2      (4, [])\n",
       "3      (7, [])\n",
       "4      (8, [])\n",
       "5      (9, [])\n",
       "6     (10, [])\n",
       "7     (11, [])\n",
       "8     (13, [])\n",
       "9     (14, [])\n",
       "10    (16, [])\n",
       "11    (17, [])\n",
       "12    (18, [])\n",
       "13    (19, [])\n",
       "14    (20, [])\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "item_features_df['cat_val'] = item_features_df['feature_category_id'].apply(str)+ '-' + item_features_df['feature_value_id'].apply(str)\n",
    "#item_features_df['cat_val'] = item_features_df['feature_category_id'].apply(str)\n",
    "\n",
    "#top_most_valuable_item_features = item_features_df['cat_val'].value_counts();\n",
    "#top_most_valuable_item_features = top_most_valuable_item_features[\\\n",
    "#            (top_most_valuable_item_features>5000)&(top_most_valuable_item_features<10000)]\n",
    "#\n",
    "#top_most_valuable_item_features = set(top_most_valuable_item_features.index)\n",
    "#def most_valuable(features):\n",
    "#    return list((top_most_valuable_item_features) & set(features))\n",
    "\n",
    "# Aggregate by item_id and add category and value as list of features\n",
    "item_features = item_features_df.groupby('item_id').agg(\n",
    "    item_id=pd.NamedAgg(column=\"item_id\", aggfunc=\"min\"),\n",
    "    cat_val=pd.NamedAgg(column=\"cat_val\", aggfunc=list),\n",
    ").reset_index(drop=True).progress_apply( \\\n",
    "#    lambda row: (row['item_id'], most_valuable(row['cat_val'])), axis = 1) \n",
    "    lambda row: (row['item_id'], []), axis = 1) \n",
    "\n",
    "\n",
    "item_features.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19befe",
   "metadata": {},
   "source": [
    "Building the interactions of the form: iterable tuple (session_id, item_id, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2619a67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e3d6a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>score</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4544540</th>\n",
       "      <td>4254727</td>\n",
       "      <td>2447</td>\n",
       "      <td>2021-03-11 14:11:29.645</td>\n",
       "      <td>m3</td>\n",
       "      <td>h14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.404127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id  item_id                    date month hour  score  \\\n",
       "4544540     4254727     2447 2021-03-11 14:11:29.645    m3  h14      3   \n",
       "\n",
       "           weight  \n",
       "4544540  0.404127  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions_df['score'] = train_sessions_df.groupby(['session_id']).cumcount()+1\n",
    "#\n",
    "# I give weight on each view of item and as more as it goes the score is increasing but never reach 1\n",
    "# this is why we have np.tanh(x/7), and number 7 is empirical\n",
    "#\n",
    "train_sessions_df['weight'] = train_sessions_df['score'].apply(lambda x: np.tanh(x/7))\n",
    "\n",
    "#train_sessions_df['views'] = train_sessions_df.groupby(['session_id']).count();\n",
    "train_sessions_df[(train_sessions_df['item_id']==2447)&(train_sessions_df['session_id']==4254727)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec6ca244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 4743820/4743820 [01:03<00:00, 74638.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 980000/980000 [00:13<00:00, 71450.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Give tanh((cumcount()+1)/5)) for just view in the session\n",
    "# First view has less weight, second has more, and so on\n",
    "# and 1.0 for a purchase\n",
    "train_interactions1 = train_sessions_df.progress_apply(\n",
    "    lambda row: (row['session_id'], row['item_id'], row['weight']), axis = 1)  \n",
    "train_interactions2 = train_p_df.progress_apply(\n",
    "    lambda row: (row['session_id'], row['item_id'], 1), axis = 1) \n",
    "\n",
    "train_interactions = pd.concat([train_interactions1, train_interactions2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdf5faea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (3, 9655, 0.14189319376693255)\n",
       "1     (3, 9655, 0.2781854903257024)\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_interactions.reset_index(inplace=True)\n",
    "#print(f\"train_interactions.info() : {train_interactions.info()}\")\n",
    "train_interactions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1432a31",
   "metadata": {},
   "source": [
    "## Build Light FM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "070ff41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature values: []...\n",
      "Item feature values: []...\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "item_features_counter = Counter()\n",
    "item_features.map(lambda x: item_features_counter.update(x[1]))\n",
    "item_features_vals = list(item_features_counter.keys())\n",
    "\n",
    "user_features_counter = Counter()\n",
    "user_features.map(lambda x: user_features_counter.update(x[1]))\n",
    "user_features_vals = list(user_features_counter.keys())\n",
    "\n",
    "print(f\"User feature values: {user_features_vals[:30]}...\")\n",
    "print(f\"Item feature values: {item_features_vals[:30]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38ebb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm\n",
    "from lightfm import cross_validation\n",
    "\n",
    "\n",
    "ds = Dataset()\n",
    "ds.fit( \\\n",
    "       train_sessions_df['session_id'].unique(), \\\n",
    "       item_features_df['item_id'].unique(), \\\n",
    "       item_features=item_features_vals, \\\n",
    "       user_features=user_features_vals)\n",
    "item_features_ds                  = ds.build_item_features(item_features)\n",
    "train_interactions_ds, weights_ds = ds.build_interactions(train_interactions)\n",
    "user_features_ds                  = ds.build_user_features(user_features)\n",
    "\n",
    "(trn_interactions_ds, tst_interactions_ds) = \\\n",
    "    lightfm.cross_validation.random_train_test_split(train_interactions_ds, test_percentage=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74deee44",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce9315d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:48<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(\n",
    "    no_components=20,\n",
    "    learning_rate=0.02,\n",
    "    loss='warp',\n",
    "    random_state=42)\n",
    "\n",
    "model.fit(\n",
    "    trn_interactions_ds,\n",
    "    item_features=item_features_ds,\n",
    "    user_features=user_features_ds, \n",
    "    epochs=20, num_threads=4, verbose=True)\n",
    "\n",
    "(user_map, feature_map, item_map, item_feature_map) = ds.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666e43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f5d31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings(model, sessions_or_purchase_df, items_to_predict) :\n",
    "    session_ids = pd.Series(sessions_or_purchase_df['session_id'].unique())\n",
    "    all_users = session_ids \\\n",
    "        .apply(lambda x: user_map[x]).to_numpy()\n",
    "    all_available_items = items_to_predict.apply(lambda x: item_map[x]).to_numpy()\n",
    "    users =[]\n",
    "    items =[]\n",
    "    for user_item_tuple in product(all_users, all_available_items):\n",
    "        users.append(user_item_tuple[0])\n",
    "        items.append(user_item_tuple[1])\n",
    "    preds = model.predict(np.array(users), np.array(items))\n",
    "    \n",
    "    session_ids_expanded = []\n",
    "    item_ids_expanded = []\n",
    "    for tup in product(session_ids, items_to_predict):\n",
    "        session_ids_expanded.append(tup[0])\n",
    "        item_ids_expanded.append(tup[1])\n",
    "    \n",
    "    \n",
    "    df_score = pd.DataFrame({'session_id': np.array(session_ids_expanded), \\\n",
    "                      'item_id':np.array(item_ids_expanded) , \\\n",
    "                      'score':np.array(preds)})\n",
    "    return df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a5a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b9c12ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items to predict:  2500\n"
     ]
    }
   ],
   "source": [
    "# Determine which items to predict\n",
    "# For the submission we load from \"candidate_items.csv\" but for\n",
    "# initial testing we must take them from train_sessions.\n",
    "\n",
    "#items_to_predict_array = train_sessions_df['item_id'].unique()\n",
    "\n",
    "# Recommend from most sold items\n",
    "items_to_predict_array = \\\n",
    "     list(train_sessions_df['item_id'].value_counts()[0:2500].keys())\n",
    "\n",
    "print('Items to predict: ', len(items_to_predict_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0190eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = predict_ratings(model, test_p_df[0:20000], \\\n",
    "                    pd.Series(items_to_predict_array))\n",
    "t1 = t.sort_values(['score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23b79106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobi/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>186</td>\n",
       "      <td>8060</td>\n",
       "      <td>3.418700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11084</th>\n",
       "      <td>186</td>\n",
       "      <td>27613</td>\n",
       "      <td>3.090018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>186</td>\n",
       "      <td>17089</td>\n",
       "      <td>3.075849</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21765</th>\n",
       "      <td>186</td>\n",
       "      <td>9184</td>\n",
       "      <td>2.938087</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26950</th>\n",
       "      <td>186</td>\n",
       "      <td>18657</td>\n",
       "      <td>2.888411</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802352</th>\n",
       "      <td>4439953</td>\n",
       "      <td>27852</td>\n",
       "      <td>1.878278</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813164</th>\n",
       "      <td>4439953</td>\n",
       "      <td>17826</td>\n",
       "      <td>1.872271</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824753</th>\n",
       "      <td>4439953</td>\n",
       "      <td>6905</td>\n",
       "      <td>1.865824</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833599</th>\n",
       "      <td>4439953</td>\n",
       "      <td>11742</td>\n",
       "      <td>1.860946</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841517</th>\n",
       "      <td>4439953</td>\n",
       "      <td>4193</td>\n",
       "      <td>1.856672</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  item_id     score  rank\n",
       "2332           186     8060  3.418700     1\n",
       "11084          186    27613  3.090018     2\n",
       "11848          186    17089  3.075849     3\n",
       "21765          186     9184  2.938087     4\n",
       "26950          186    18657  2.888411     5\n",
       "...            ...      ...       ...   ...\n",
       "802352     4439953    27852  1.878278    96\n",
       "813164     4439953    17826  1.872271    97\n",
       "824753     4439953     6905  1.865824    98\n",
       "833599     4439953    11742  1.860946    99\n",
       "841517     4439953     4193  1.856672   100\n",
       "\n",
       "[2000000 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrameGroupBy: The function passed to apply must take a dataframe \n",
    "# as its first argument and return a DataFrame\n",
    "# From the other side \"cumcount()\" is used to count in the group\n",
    "t1['rank'] = t1.groupby('session_id').cumcount()+1\n",
    "\n",
    "\n",
    "result_df = t1[t1['rank']<=100]#.drop('score', axis=1)\n",
    "result_df.reset_index(inplace=True)\n",
    "result_df.drop(['index'], inplace=True, axis=1)\n",
    "\n",
    "result_df = result_df.sort_values( \\\n",
    "        by=['session_id', 'rank'],ascending=True)\n",
    "#result_df.reset_index(inplace=True)\n",
    "#result_df.to_csv(\"result_df.csv\")\n",
    "result_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a296e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 20000/20000 [00:51<00:00, 388.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0625947655473263"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_p_df[test_p_df['session_id'].isin({2692943,1211445})]\n",
    "\n",
    "calc_mrr(result_df, test_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81ec75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p_df.to_csv(\"test_p_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903a475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
