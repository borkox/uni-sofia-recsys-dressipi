{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74c05a9",
   "metadata": {},
   "source": [
    "## LightFM recommendation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0307b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4e82322",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases_df = pd.read_csv(\"../data/dressipi_recsys2022/train_purchases.csv\", parse_dates=['date'])\n",
    "train_sessions_df = pd.read_csv(\"../data/dressipi_recsys2022/train_sessions.csv\" , parse_dates=['date'])\n",
    "item_features_df = pd.read_csv(\"../data/dressipi_recsys2022/item_features.csv\")\n",
    "candidate_items_df = pd.read_csv(\"../data/dressipi_recsys2022/candidate_items.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b14d78",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6a57743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_sessions_set)=20000\n",
      "len(train_p_df)=980000 train purchases\n",
      "len(test_p_df)=20000   test purchases\n",
      "len(train_s_df)=4649917 train sessions\n",
      "len(test_s_df)=93903   test sessions\n"
     ]
    }
   ],
   "source": [
    "# Test set is\n",
    "train_p_df, test_p_df = train_test_split(train_purchases_df, test_size=0.02)\n",
    "test_sessions_set = set(test_p_df['session_id'])\n",
    "\n",
    "train_s_df = train_sessions_df[~train_sessions_df['session_id'].isin(test_sessions_set)]\n",
    "test_s_df = train_sessions_df[train_sessions_df['session_id'].isin(test_sessions_set)]\n",
    "\n",
    "print(f\"len(test_sessions_set)={len(test_sessions_set)}\")\n",
    "print(f\"len(train_p_df)={len(train_p_df)} train purchases\")\n",
    "print(f\"len(test_p_df)={len(test_p_df)}   test purchases\")\n",
    "print(f\"len(train_s_df)={len(train_s_df)} train sessions\")\n",
    "print(f\"len(test_s_df)={len(test_s_df)}   test sessions\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c01211",
   "metadata": {},
   "source": [
    "## The task is to submit a csv that has 100 ranked predictions for each query session.\n",
    "Header and columns as in the example below. Header is required. The order of rows does not matter for the evaluation system but we recommend to sort the file by session_id and rank for easier manual inspection. \n",
    "<pre>\n",
    "session_id,item_id,rank\n",
    "1,100,1\n",
    "1,105,2\n",
    "1,107,3\n",
    "...\n",
    "1,101,100\n",
    "2,108,1\n",
    "2,107,2\n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b88f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightfm in /home/bobi/anaconda3/lib/python3.9/site-packages (1.16)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (0.24.2)\n",
      "Requirement already satisfied: numpy in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (1.22.3)\n",
      "Requirement already satisfied: requests in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (1.26.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from scikit-learn->lightfm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/bobi/anaconda3/lib/python3.9/site-packages (from scikit-learn->lightfm) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca4dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826d521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mrr (Mean reciprocal rank)\n",
    "def calc_mrr(result_df, test_df):\n",
    "    mrr = 0\n",
    "    # Iterate all sessions\n",
    "    for sess_id in test_df['session_id']:\n",
    "        # Make view for only this session with all ranked\n",
    "        ranked = result_df[result_df['session_id']==sess_id]['item_id'].reset_index(drop=True)\n",
    "        real_item_id = test_df[test_df['session_id']==sess_id]['item_id'].reset_index(drop=True)[0] \n",
    "        first_rank = 100\n",
    "        found_t = ranked[ranked == real_item_id]\n",
    "        if len(found_t)!=0 :\n",
    "            first_rank = found_t.index[0]+1\n",
    "        mrr =mrr+ 1/first_rank\n",
    "        \n",
    "    mrr = mrr / test_df['session_id'].nunique()\n",
    "    return mrr\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f4381da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of method is commented\n",
    "#calc_mrr(pd.DataFrame.from_dict({'session_id':[1,1,2,2,2,3,3,3], 'item_id':[1,2,3,4,5,6,7,8]}),\\\n",
    "#                     pd.DataFrame.from_dict({'session_id':[1,2,3], 'item_id':[2,5,8]}))\n",
    "#(1/2 + 1/3 + 1/100)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c797f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightfm.data import Dataset\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b79603",
   "metadata": {},
   "source": [
    "## Start building the feature for light FM\n",
    "User features are of the form tuple iterable tuple (session_id, [month, hour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bc884a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4002/2386257759.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_s_df['month']='m' + train_s_df['date'].dt.month.apply(str)\n",
      "/tmp/ipykernel_4002/2386257759.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_s_df['hour']='h' + train_s_df['date'].dt.hour.apply(str)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4002/2386257759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m ).reset_index(drop=True).apply(lambda row: (row['session_id'], list(row['month']) + (list(row['hour']))), axis = 1) )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0muser_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "train_s_df['month']='m' + train_s_df['date'].dt.month.apply(str)\n",
    "train_s_df['hour']='h' + train_s_df['date'].dt.hour.apply(str)\n",
    "\n",
    "# Aggregate by sessionId and add hour and month as list of features\n",
    "user_features = list(train_s_df.groupby('session_id').agg(\n",
    "    session_id=pd.NamedAgg(column=\"session_id\", aggfunc=\"min\"),\n",
    "    month=pd.NamedAgg(column=\"month\", aggfunc=set),\n",
    "    hour=pd.NamedAgg(column=\"hour\", aggfunc=set),\n",
    ").reset_index(drop=True).apply(lambda row: (row['session_id'], list(row['month']) + (list(row['hour']))), axis = 1) )\n",
    "\n",
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab20e17",
   "metadata": {},
   "source": [
    "Item features are tuples of this form: iterable tuple (item_id, [category1-value1, category2-value2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb5212ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (2, [56-365, 62-801, 68-351, 33-802, 72-75, 29...\n",
       "1    (3, [56-365, 69-592, 68-14, 17-378, 32-902, 11...\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features_df['cat_val'] = item_features_df['feature_category_id'].apply(str)+ '-' + item_features_df['feature_value_id'].apply(str)\n",
    "\n",
    "# Aggregate by item_id and add category and value as list of features\n",
    "item_features = item_features_df.groupby('item_id').agg(\n",
    "    item_id=pd.NamedAgg(column=\"item_id\", aggfunc=\"min\"),\n",
    "    cat_val=pd.NamedAgg(column=\"cat_val\", aggfunc=list),\n",
    ").reset_index(drop=True).apply(lambda row: (row['item_id'], row['cat_val']), axis = 1) \n",
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19befe",
   "metadata": {},
   "source": [
    "Building the interactions of the form: iterable tuple (session_id, item_id, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec6ca244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give 0.3 weight for just view in the session\n",
    "# and 1.0 for a purchase\n",
    "train_interactions1 = train_s_df.apply(\n",
    "    lambda row: (row['session_id'], row['item_id'], 0.3), axis = 1)  \n",
    "train_interactions2 = train_p_df.apply(\n",
    "    lambda row: (row['session_id'], row['item_id'], 1), axis = 1) \n",
    "\n",
    "train_interactions = pd.concat([train_interactions1, train_interactions2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdf5faea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (3, 9655, 0.3)\n",
       "1    (3, 9655, 0.3)\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_interactions.reset_index(inplace=True)\n",
    "#print(f\"train_interactions.info() : {train_interactions.info()}\")\n",
    "train_interactions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7ba7f",
   "metadata": {},
   "source": [
    "## Build Light FM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad43afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature values: ['m10', 'h20', 'm4', 'h9', 'm3', 'h6', 'h11', 'm5', 'h23', 'h7', 'h8', 'm12', 'h19', 'h18', 'h13', 'm8', 'm11', 'h22', 'm2', 'h21', 'm6', 'h5', 'h14', 'h17', 'm7', 'h15', 'h12', 'h10', 'm1', 'h16']...\n",
      "Item feature values: ['56-365', '62-801', '68-351', '33-802', '72-75', '29-123', '16-38', '50-76', '61-462', '53-6', '7-394', '69-885', '47-123', '69-592', '68-14', '17-378', '32-902', '11-859', '45-559', '7-452', '19-254', '46-825', '61-706', '73-544', '55-129', '63-861', '50-240', '59-180', '4-618', '5-605']...\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "item_features_counter = Counter()\n",
    "item_features.map(lambda x: item_features_counter.update(x[1]))\n",
    "item_features_vals = list(item_features_counter.keys())\n",
    "\n",
    "user_features_counter = Counter()\n",
    "user_features.map(lambda x: user_features_counter.update(x[1]))\n",
    "user_features_vals = list(user_features_counter.keys())\n",
    "\n",
    "print(f\"User feature values: {user_features_vals[:30]}...\")\n",
    "print(f\"Item feature values: {item_features_vals[:30]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "709bbcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2506 in train_s_df['session_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd3612c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm\n",
    "from lightfm import cross_validation\n",
    "\n",
    "\n",
    "ds = Dataset()\n",
    "ds.fit(train_p_df['session_id'],item_features_df['item_id'].unique(), item_features=item_features_vals, user_features=user_features_vals)\n",
    "item_features_ds                  = ds.build_item_features(item_features)\n",
    "train_interactions_ds, weights_ds = ds.build_interactions(train_interactions)\n",
    "user_features_ds                  = ds.build_user_features(user_features)\n",
    "\n",
    "(trn_interactions_ds, tst_interactions_ds) = lightfm.cross_validation.random_train_test_split(train_interactions_ds, test_percentage=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95325ed0",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e280b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 35/35 [12:35<00:00, 21.58s/it]\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(\n",
    "    no_components=10,\n",
    "    learning_rate=0.02,\n",
    "    loss='warp',\n",
    "    random_state=42)\n",
    "\n",
    "model.fit(\n",
    "    trn_interactions_ds,\n",
    "    item_features=item_features_ds,\n",
    "    user_features=user_features_ds, \n",
    "    epochs=35, num_threads=4, verbose=True)\n",
    "\n",
    "(user_map, feature_map, item_map, item_feature_map) = ds.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca8827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "684aed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings(model, sessions_or_purchase_df) :\n",
    "    all_users = pd.Series( \\\n",
    "        sessions_or_purchase_df['session_id'].unique()) \\\n",
    "        .apply(lambda x: user_map[x]).to_numpy()\n",
    "    all_available_items = candidate_items_df['item_id'].apply(lambda x: item_map[x]).to_numpy()\n",
    "    users =[]\n",
    "    items =[]\n",
    "    for user_item_tuple in product(all_users, all_available_items):\n",
    "        users.append(user_item_tuple[0])\n",
    "        items.append(user_item_tuple[1])\n",
    "    preds = model.predict(np.array(users), np.array(items))\n",
    "    return pd.Series(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "645176e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.122347\n",
       "1      -0.738998\n",
       "2      -1.847721\n",
       "3      -0.495834\n",
       "4      -0.912241\n",
       "          ...   \n",
       "9975   -0.888461\n",
       "9976   -0.910609\n",
       "9977   -0.388725\n",
       "9978    2.862002\n",
       "9979   -0.292852\n",
       "Length: 9980, dtype: float32"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ratings(model, train_p_df[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac106f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
