{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74c05a9",
   "metadata": {},
   "source": [
    "## LightFM recommendation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0307b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e82322",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_purchases_df = pd.read_csv(\"../data/dressipi_recsys2022/train_purchases.csv\", parse_dates=['date'])\n",
    "train_sessions_df = pd.read_csv(\"../data/dressipi_recsys2022/train_sessions.csv\" , parse_dates=['date'])\n",
    "item_features_df = pd.read_csv(\"../data/dressipi_recsys2022/item_features.csv\")\n",
    "candidate_items_df = pd.read_csv(\"../data/dressipi_recsys2022/candidate_items.csv\")\n",
    "test_leaderboard_sessions_df = pd.read_csv(\"../data/dressipi_recsys2022/test_leaderboard_sessions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c01211",
   "metadata": {},
   "source": [
    "## The task is to submit a csv that has 100 ranked predictions for each query session.\n",
    "Header and columns as in the example below. Header is required. The order of rows does not matter for the evaluation system but we recommend to sort the file by session_id and rank for easier manual inspection. \n",
    "<pre>\n",
    "session_id,item_id,rank\n",
    "1,100,1\n",
    "1,105,2\n",
    "1,107,3\n",
    "...\n",
    "1,101,100\n",
    "2,108,1\n",
    "2,107,2\n",
    "...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b88f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightfm in /home/bobi/anaconda3/lib/python3.9/site-packages (1.16)\n",
      "Requirement already satisfied: numpy in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (1.22.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (1.8.0)\n",
      "Requirement already satisfied: requests in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (2.26.0)\n",
      "Requirement already satisfied: scikit-learn in /home/bobi/anaconda3/lib/python3.9/site-packages (from lightfm) (0.24.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bobi/anaconda3/lib/python3.9/site-packages (from requests->lightfm) (2021.10.8)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/bobi/anaconda3/lib/python3.9/site-packages (from scikit-learn->lightfm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/bobi/anaconda3/lib/python3.9/site-packages (from scikit-learn->lightfm) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca4dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "826d521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Calculate Mrr (Mean reciprocal rank)\n",
    "def calc_mrr(result_df, test_df):\n",
    "    mrr = 0\n",
    "    # Iterate all sessions\n",
    "    for sess_id in tqdm(test_df['session_id']):\n",
    "        # Make view for only this session with all ranked\n",
    "        ranked = result_df[result_df['session_id']==sess_id]['item_id'].reset_index(drop=True)\n",
    "        real_item_id = test_df[test_df['session_id']==sess_id]['item_id'].reset_index(drop=True)[0] \n",
    "        first_rank = 100\n",
    "        found_t = ranked[ranked == real_item_id]\n",
    "        if len(found_t)!=0 :\n",
    "            first_rank = found_t.index[0]+1\n",
    "        #    print(f'sess_id={sess_id},real_item_id={real_item_id},first_rank={first_rank}')\n",
    "        #else:\n",
    "        #    print(f'sess_id={sess_id},real_item_id={real_item_id}, not found')\n",
    "            \n",
    "        mrr =mrr+ 1/first_rank\n",
    "        \n",
    "    mrr = mrr / test_df['session_id'].nunique()\n",
    "    return mrr\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4381da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of method is commented\n",
    "#calc_mrr(pd.DataFrame.from_dict({'session_id':[1,1,2,2,2,3,3,3], 'item_id':[1,2,3,4,5,6,7,8]}),\\\n",
    "#                     pd.DataFrame.from_dict({'session_id':[1,2,3], 'item_id':[2,5,8]}))\n",
    "#(1/2 + 1/3 + 1/100)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c797f6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightfm.data import Dataset\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b79603",
   "metadata": {},
   "source": [
    "## Start building the feature for light FM\n",
    "User features are of the form tuple iterable tuple (session_id, [month, hour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc884a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (3, [])\n",
       "1    (13, [])\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions_df['month']='m' + train_sessions_df['date'].dt.month.apply(str)\n",
    "train_sessions_df['hour']='h' + train_sessions_df['date'].dt.hour.apply(str)\n",
    "\n",
    "# Aggregate by sessionId and add hour and month as list of features\n",
    "user_features = train_sessions_df.groupby('session_id').agg(\n",
    "    session_id=pd.NamedAgg(column=\"session_id\", aggfunc=\"min\"),\n",
    "    month=pd.NamedAgg(column=\"month\", aggfunc=set),\n",
    "    hour=pd.NamedAgg(column=\"hour\", aggfunc=set),\n",
    ").reset_index(drop=True).apply( \\\n",
    "        lambda row: (row['session_id'], []), axis = 1)\n",
    "        #lambda row: (row['session_id'], list(row['month']) + (list(row['hour']))), axis = 1)\n",
    "\n",
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab20e17",
   "metadata": {},
   "source": [
    "Item features are tuples of this form: iterable tuple (item_id, [category1-value1, category2-value2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63faef6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5212ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 23691/23691 [00:00<00:00, 136425.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      (2, [])\n",
       "1      (3, [])\n",
       "2      (4, [])\n",
       "3      (7, [])\n",
       "4      (8, [])\n",
       "5      (9, [])\n",
       "6     (10, [])\n",
       "7     (11, [])\n",
       "8     (13, [])\n",
       "9     (14, [])\n",
       "10    (16, [])\n",
       "11    (17, [])\n",
       "12    (18, [])\n",
       "13    (19, [])\n",
       "14    (20, [])\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "item_features_df['cat_val'] = item_features_df['feature_category_id'].apply(str)+ '-' + item_features_df['feature_value_id'].apply(str)\n",
    "#item_features_df['cat_val'] = item_features_df['feature_category_id'].apply(str)\n",
    "\n",
    "#top_most_valuable_item_features = item_features_df['cat_val'].value_counts();\n",
    "#top_most_valuable_item_features = top_most_valuable_item_features[\\\n",
    "#            (top_most_valuable_item_features>5000)&(top_most_valuable_item_features<10000)]\n",
    "#\n",
    "#top_most_valuable_item_features = set(top_most_valuable_item_features.index)\n",
    "#def most_valuable(features):\n",
    "#    return list((top_most_valuable_item_features) & set(features))\n",
    "\n",
    "# Aggregate by item_id and add category and value as list of features\n",
    "item_features = item_features_df.groupby('item_id').agg(\n",
    "    item_id=pd.NamedAgg(column=\"item_id\", aggfunc=\"min\"),\n",
    "    cat_val=pd.NamedAgg(column=\"cat_val\", aggfunc=list),\n",
    ").reset_index(drop=True).progress_apply( \\\n",
    "#    lambda row: (row['item_id'], most_valuable(row['cat_val'])), axis = 1) \n",
    "    lambda row: (row['item_id'], []), axis = 1) \n",
    "\n",
    "\n",
    "item_features.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19befe",
   "metadata": {},
   "source": [
    "Building the interactions of the form: iterable tuple (session_id, item_id, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b758a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7f9f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>score</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4544540</th>\n",
       "      <td>4254727</td>\n",
       "      <td>2447</td>\n",
       "      <td>2021-03-11 14:11:29.645</td>\n",
       "      <td>m3</td>\n",
       "      <td>h14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.404127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id  item_id                    date month hour  score  \\\n",
       "4544540     4254727     2447 2021-03-11 14:11:29.645    m3  h14      3   \n",
       "\n",
       "           weight  \n",
       "4544540  0.404127  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions_df['score'] = train_sessions_df.groupby(['session_id']).cumcount()+1\n",
    "test_leaderboard_sessions_df['score'] = test_leaderboard_sessions_df.groupby(['session_id']).cumcount()+1\n",
    "#\n",
    "# I give weight on each view of item and as more as it goes the score is increasing but never reach 1\n",
    "# this is why we have np.tanh(x/7), and number 7 is empirical\n",
    "#\n",
    "train_sessions_df['weight'] = train_sessions_df['score'].apply(lambda x: np.tanh(x/7))\n",
    "test_leaderboard_sessions_df['weight'] = test_leaderboard_sessions_df['score'].apply(lambda x: np.tanh(x/7))\n",
    "\n",
    "#train_sessions_df['views'] = train_sessions_df.groupby(['session_id']).count();\n",
    "train_sessions_df[(train_sessions_df['item_id']==2447)&(train_sessions_df['session_id']==4254727)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6ca244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 4743820/4743820 [01:11<00:00, 66356.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 229354/229354 [00:03<00:00, 74693.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1000000/1000000 [00:14<00:00, 69704.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Give tanh((cumcount()+1)/5)) for just view in the session\n",
    "# First view has less weight, second has more, and so on\n",
    "# and 1.0 for a purchase\n",
    "train_interactions1 = train_sessions_df.progress_apply(\n",
    "    lambda row: (row['session_id'], row['item_id'], row['weight']), axis = 1)  \n",
    "train_interactions2 = test_leaderboard_sessions_df.progress_apply(\n",
    "    lambda row: (row['session_id'], row['item_id'], row['weight']), axis = 1)  \n",
    "train_interactions3 = train_purchases_df.progress_apply(\n",
    "    lambda row: (row['session_id'], row['item_id'], 1), axis = 1) \n",
    "\n",
    "train_interactions = pd.concat([train_interactions1, train_interactions2, train_interactions3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf5faea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (3, 9655, 0.14189319376693255)\n",
       "1     (3, 9655, 0.2781854903257024)\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_interactions.reset_index(inplace=True)\n",
    "#print(f\"train_interactions.info() : {train_interactions.info()}\")\n",
    "train_interactions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb72bf",
   "metadata": {},
   "source": [
    "## Build Light FM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3bb040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature values: []...\n",
      "Item feature values: []...\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "item_features_counter = Counter()\n",
    "item_features.map(lambda x: item_features_counter.update(x[1]))\n",
    "item_features_vals = list(item_features_counter.keys())\n",
    "\n",
    "user_features_counter = Counter()\n",
    "user_features.map(lambda x: user_features_counter.update(x[1]))\n",
    "user_features_vals = list(user_features_counter.keys())\n",
    "\n",
    "print(f\"User feature values: {user_features_vals[:30]}...\")\n",
    "print(f\"Item feature values: {item_features_vals[:30]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05766854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5e6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm\n",
    "from lightfm import cross_validation\n",
    "\n",
    "\n",
    "ds = Dataset()\n",
    "ds.fit( \\\n",
    "       np.concatenate([train_sessions_df['session_id'].unique(), test_leaderboard_sessions_df['session_id'].unique()]), \\\n",
    "       item_features_df['item_id'].unique(), \\\n",
    "       item_features=item_features_vals, \\\n",
    "       user_features=user_features_vals)\n",
    "item_features_ds                  = ds.build_item_features(item_features)\n",
    "train_interactions_ds, weights_ds = ds.build_interactions(train_interactions)\n",
    "user_features_ds                  = ds.build_user_features(user_features)\n",
    "\n",
    "(trn_interactions_ds, tst_interactions_ds) = \\\n",
    "    lightfm.cross_validation.random_train_test_split(train_interactions_ds, test_percentage=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5639d",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e32455b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [01:35<00:00,  3.81s/it]\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(\n",
    "    no_components=60,\n",
    "    learning_rate=0.02,\n",
    "    loss='warp',\n",
    "    random_state=42)\n",
    "\n",
    "model.fit(\n",
    "    trn_interactions_ds,\n",
    "    item_features=item_features_ds,\n",
    "    user_features=user_features_ds, \n",
    "    epochs=25, num_threads=8, verbose=True)\n",
    "\n",
    "(user_map, feature_map, item_map, item_feature_map) = ds.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac87a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d41100ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings(model, sessions_or_purchase_df, items_to_predict) :\n",
    "    session_ids = pd.Series(sessions_or_purchase_df['session_id'].unique())\n",
    "    all_users = session_ids \\\n",
    "        .apply(lambda x: user_map[x]).to_numpy()\n",
    "    all_available_items = items_to_predict.apply(lambda x: item_map[x]).to_numpy()\n",
    "    users =[]\n",
    "    items =[]\n",
    "    for user_item_tuple in tqdm(product(all_users, all_available_items)):\n",
    "        users.append(user_item_tuple[0])\n",
    "        items.append(user_item_tuple[1])\n",
    "    preds = model.predict(np.array(users), np.array(items))\n",
    "    \n",
    "    session_ids_expanded = []\n",
    "    item_ids_expanded = []\n",
    "    for tup in tqdm(product(session_ids, items_to_predict)):\n",
    "        session_ids_expanded.append(tup[0])\n",
    "        item_ids_expanded.append(tup[1])\n",
    "    \n",
    "    \n",
    "    df_score = pd.DataFrame({'session_id': np.array(session_ids_expanded), \\\n",
    "                      'item_id':np.array(item_ids_expanded) , \\\n",
    "                      'score':np.array(preds)})\n",
    "    return df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2a894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbf2b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items to predict:  4990\n"
     ]
    }
   ],
   "source": [
    "# Determine which items to predict\n",
    "# For the submission we load from \"candidate_items.csv\" but for\n",
    "# initial testing we must take them from train_sessions.\n",
    "\n",
    "#items_to_predict_array = train_sessions_df['item_id'].unique()\n",
    "\n",
    "# Recommend from most sold items\n",
    "items_to_predict_array = \\\n",
    "     list(candidate_items_df['item_id'].value_counts().keys())\n",
    "\n",
    "print('Items to predict: ', len(items_to_predict_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f4409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_leaderboard_sessions_df['session_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede4da4",
   "metadata": {},
   "source": [
    "# It is too big array and Jupyter dies, so I split \"test_leaderboard_sessions_df\" in two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44309f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_final(model, sessions, items_to_predict_array):\n",
    "    t = predict_ratings(model, sessions, \\\n",
    "                    pd.Series(items_to_predict_array))\n",
    "    t1 = t.sort_values(['score'],ascending=False)\n",
    "    # DataFrameGroupBy: The function passed to apply must take a dataframe \n",
    "    # as its first argument and return a DataFrame\n",
    "    # From the other side \"cumcount()\" is used to count in the group\n",
    "    t1['rank'] = t1.groupby('session_id').cumcount()+1\n",
    "\n",
    "\n",
    "    result_df = t1[t1['rank']<=100].drop('score', axis=1)\n",
    "    result_df.reset_index(inplace=True)\n",
    "    result_df.drop(['index'], inplace=True, axis=1)\n",
    "\n",
    "    result_df = result_df.sort_values( \\\n",
    "            by=['session_id', 'rank'],ascending=True)\n",
    "    result_df.reset_index(inplace=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d3120f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53862060it [00:14, 3597094.26it/s]\n",
      "53862060it [00:13, 4085446.12it/s]\n",
      "53892000it [00:13, 4000542.62it/s]\n",
      "53892000it [00:13, 3870239.98it/s]\n",
      "54730320it [00:12, 4389932.46it/s]\n",
      "54730320it [00:12, 4270327.48it/s]\n",
      "54580620it [00:12, 4315133.97it/s]\n",
      "54580620it [00:14, 3897682.45it/s]\n",
      "32454960it [00:07, 4299354.63it/s]\n",
      "32454960it [00:08, 3839224.67it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1 = predict_final(model, test_leaderboard_sessions_df[0:50000], items_to_predict_array)\n",
    "df2 = predict_final(model, test_leaderboard_sessions_df[50000:100000], items_to_predict_array)\n",
    "df3 = predict_final(model, test_leaderboard_sessions_df[100000:150000], items_to_predict_array)\n",
    "df4 = predict_final(model, test_leaderboard_sessions_df[150000:200000], items_to_predict_array)\n",
    "df5 = predict_final(model, test_leaderboard_sessions_df[200000:], items_to_predict_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a916adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"result_leaderboard1.csv\")\n",
    "df2.to_csv(\"result_leaderboard2.csv\")\n",
    "df3.to_csv(\"result_leaderboard3.csv\")\n",
    "df4.to_csv(\"result_leaderboard4.csv\")\n",
    "df5.to_csv(\"result_leaderboard5.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d753780",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([df1,df2,df3,df4,df5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f56215ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2530557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result_leaderboard.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdca98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
